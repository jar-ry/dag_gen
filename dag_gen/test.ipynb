{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acyclic_graph_generator import AcyclicGraphGenerator\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "def generate_data(data_config_name = \"data_config_all_issues.json\"):\n",
    "    with open(data_config_name, \"r\") as f:\n",
    "        data_config = json.load(f)\n",
    "        for dataset_group, datasets in data_config.items():\n",
    "            dataset_group_path = os.path.join(DATA_DIR, dataset_group)\n",
    "            if not os.path.isdir(DATA_DIR):\n",
    "                os.mkdir(DATA_DIR)\n",
    "            if not os.path.isdir(dataset_group_path):\n",
    "                os.mkdir(dataset_group_path)\n",
    "            for dataset_name, generator_config in datasets.items():\n",
    "                dataset_path = os.path.join(dataset_group_path, dataset_name)\n",
    "                # If directory doesn't exist or isn't empty\n",
    "                if not os.path.isdir(dataset_path):\n",
    "                    os.mkdir(dataset_path)\n",
    "                if len(os.listdir(dataset_path)) == 0:\n",
    "                    print(\"Generating: \", dataset_path)\n",
    "                    generator = AcyclicGraphGenerator(**generator_config)\n",
    "                    generator.generate_to_folder(data_path=dataset_path, data_index=1)\n",
    "                else:\n",
    "                    print(\"Skipping: \", dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating:  data\\mix_mechanism\\small_mixed_all_issues_1\n",
      "Generate Count: 1\n",
      "HERE2132312\n",
      "j: 1\n",
      "nb_parents: 0\n",
      "HERE2132312\n",
      "j: 2\n",
      "nb_parents: 0\n",
      "HERE2132312\n",
      "j: 3\n",
      "nb_parents: 0\n",
      "HERE2132312\n",
      "j: 4\n",
      "nb_parents: 1\n",
      "HERE2132312\n",
      "j: 5\n",
      "nb_parents: 1\n",
      "HERE2132312\n",
      "j: 6\n",
      "nb_parents: 0\n",
      "HERE2132312\n",
      "j: 7\n",
      "nb_parents: 0\n",
      "HERE2132312\n",
      "j: 8\n",
      "nb_parents: 1\n",
      "HERE2132312\n",
      "j: 9\n",
      "nb_parents: 0\n",
      "edge:  [(0, 2), (0, 4), (0, 7), (0, 8), (0, 9), (8, 1), (8, 3), (8, 5)]\n",
      "number_nodes_with_two_or_more_parents less than confounders\n",
      "HERE4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\python37_ml\\lib\\site-packages\\pygraphviz\\agraph.py:1390: RuntimeWarning: Warning: node '0', graph '' size too small for label\n",
      "Warning: node '2', graph '' size too small for label\n",
      "Warning: node '4', graph '' size too small for label\n",
      "Warning: node '7', graph '' size too small for label\n",
      "Warning: node '8', graph '' size too small for label\n",
      "Warning: node '9', graph '' size too small for label\n",
      "Warning: node '1', graph '' size too small for label\n",
      "Warning: node '3', graph '' size too small for label\n",
      "Warning: node '5', graph '' size too small for label\n",
      "\n",
      "  warnings.warn(b\"\".join(errors).decode(self.encoding), RuntimeWarning)\n",
      "d:\\Anaconda3\\envs\\python37_ml\\lib\\site-packages\\pygraphviz\\agraph.py:1390: RuntimeWarning: Warning: node '0', graph '' size too small for label\n",
      "Warning: node '1', graph '' size too small for label\n",
      "Warning: node '2', graph '' size too small for label\n",
      "Warning: node '4', graph '' size too small for label\n",
      "Warning: node '5', graph '' size too small for label\n",
      "Warning: node '8', graph '' size too small for label\n",
      "Warning: node '3', graph '' size too small for label\n",
      "Warning: node '6', graph '' size too small for label\n",
      "Warning: node '9', graph '' size too small for label\n",
      "Warning: node '7', graph '' size too small for label\n",
      "\n",
      "  warnings.warn(b\"\".join(errors).decode(self.encoding), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate Count: 2\n",
      "HERE2132312\n",
      "j: 1\n",
      "nb_parents: 2\n",
      "HERE2132312\n",
      "j: 2\n",
      "nb_parents: 1\n",
      "HERE2132312\n",
      "j: 3\n",
      "nb_parents: 0\n",
      "HERE2132312\n",
      "j: 4\n",
      "nb_parents: 2\n",
      "HERE2132312\n",
      "j: 5\n",
      "nb_parents: 2\n",
      "HERE2132312\n",
      "j: 6\n",
      "nb_parents: 1\n",
      "HERE2132312\n",
      "j: 7\n",
      "nb_parents: 0\n",
      "HERE2132312\n",
      "j: 8\n",
      "nb_parents: 1\n",
      "HERE2132312\n",
      "j: 9\n",
      "nb_parents: 2\n",
      "edge:  [(0, 1), (0, 2), (0, 4), (0, 5), (3, 4), (3, 5), (3, 6), (3, 9), (4, 8), (6, 9), (7, 2)]\n",
      "loop_counter: 0, max_loop: 4\n",
      "multi_parent_nodes\n",
      "[2, 4, 5, 9]\n",
      "loop_counter: 1, max_loop: 4\n",
      "multi_parent_nodes\n",
      "[2, 4, 5, 9]\n",
      "parent_to_remove\n",
      "7\n",
      "self.data.columns 0\n",
      "Index(['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'UF_V1'], dtype='object')\n",
      "self.data.columns 1\n",
      "Index(['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'UF_V1'], dtype='object')\n",
      "self.data.columns 1.5\n",
      "Index(['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V8', 'V9', 'UF_V1'], dtype='object')\n",
      "self.data.columns 2\n",
      "Index(['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V8', 'V9', 'UF_V1'], dtype='object')\n",
      "len(self.data)\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "generate_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting 1 CUDA device(s).\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "import csv\n",
    "import os.path\n",
    "from causalnex.structure import StructureModel\n",
    "from causalnex.plots import plot_structure\n",
    "from numpy import array, save, load\n",
    "from networkx import to_numpy_matrix\n",
    "from cdt.causality.graph import CAM\n",
    "import cdt\n",
    "from pandas import DataFrame\n",
    "from numpy import float32\n",
    "from os import path\n",
    "warnings.filterwarnings(\"ignore\")  # silence warnings\n",
    "\n",
    "# cdt.SETTINGS.rpath = os.getenv(\"RSCRIPT_PATH\")  # path to your r executable\n",
    "cdt.SETTINGS.rpath = 'C:\\Program Files\\R\\R-4.2.1\\\\bin\\Rscript' # path to your r executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(dag_path, plot_path, csv_path):\n",
    "    dag = np.load(dag_path)\n",
    "\n",
    "    graph = nx.from_numpy_array(dag, create_using=nx.DiGraph)\n",
    "\n",
    "    e = list(graph.edges())\n",
    "    causal_nex_graph = StructureModel(e)\n",
    "    viz = plot_structure(causal_nex_graph)  # Default CausalNex visualisation\n",
    "    viz.draw(plot_path, format=\"jpg\")\n",
    "\n",
    "    # check if the file exists\n",
    "    file_exists = os.path.isfile(csv_path)\n",
    "\n",
    "    # open the file in append mode\n",
    "    with open(csv_path, \"a\", newline=\"\") as csvfile:\n",
    "        # create a CSV writer object\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # if the file doesn't exist, write the header row\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"nodes\", \"edges\"])\n",
    "\n",
    "        # write the value to the CSV file\n",
    "        writer.writerow([graph.number_of_nodes(), graph.number_of_edges()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"details_confounder.csv\"\n",
    "dag_plot_path = \"plot_confounder.jpg\"\n",
    "dag_path = \"./data/mix_mechanism/small_mixed_all_issues_1/confounder_DAG1.npy\"\n",
    "generate_plot(dag_path, dag_plot_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
